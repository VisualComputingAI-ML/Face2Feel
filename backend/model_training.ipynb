{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32599f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "841d260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_image_dir = os.path.dirname(os.getcwd()) + \"/backend/data/FER-2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e0426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_angry = fer_image_dir + \"/train/angry/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d01c48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {file:cv2.imread(image_dir_angry+file) for file in os.listdir(image_dir_angry)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6032767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = files['im0.png']\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2 = cv2.resize(files['im0.png'], (288,288))\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "# axes[0].imshow(image1, cmap='gray')\n",
    "# axes[1].imshow(image2, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c971ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Abo/Projects/Face2Feel/backend/face_config/haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd() + \"/face_config/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae164ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2237 faces out of the total 3995 images which is 0.5599499374217772% detected\n",
      "Detected 2654 eyes out of the total 3995 images which is 0.6643304130162704% detected\n"
     ]
    }
   ],
   "source": [
    "face_detection_weights_path = (os.getcwd() + \"/face_config/haarcascade_frontalface_default.xml\")\n",
    "eye_detection_weights_path = (os.getcwd() + \"/face_config/haarcascade_eye_tree_eyeglasses.xml\")\n",
    "face_cascade = cv2.CascadeClassifier(face_detection_weights_path)\n",
    "eye_cascade = cv2.CascadeClassifier(eye_detection_weights_path)\n",
    "\n",
    "detected_face = 0\n",
    "detected_eye = 0\n",
    "for key in files:\n",
    "    picture = files[key].copy()\n",
    "    picture = cv2.resize(picture, (288, 288))\n",
    "    # plt.imshow(picture)\n",
    "    picture = cv2.cvtColor(picture, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(picture, scaleFactor=1.1, \n",
    "                                        minNeighbors=5, minSize=(60, 60),\n",
    "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    eyes = eye_cascade.detectMultiScale(picture, scaleFactor=1.1, \n",
    "                                        minNeighbors=5, minSize=(60, 60),\n",
    "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    if len(faces) > 0:\n",
    "        detected_face += 1;\n",
    "    if len(eyes) > 0:\n",
    "        detected_eye += 1;\n",
    "\n",
    "print(f\"Detected {detected_face} faces out of the total {len(files)} images which is {detected_face/len(files)}% detected\")\n",
    "print(f\"Detected {detected_eye} eyes out of the total {len(files)} images which is {detected_eye/len(files)}% detected\")\n",
    "\n",
    "# combined = image1\n",
    "# # for (x,y,w,h) in faces:\n",
    "# #     # HOG Feature Creation\n",
    "# #     cropped = image1[y:y+h, x:x+w]\n",
    "# fd, hog_image = hog(image1, orientations=8, pixels_per_cell=(8,8),\n",
    "#                     cells_per_block=(1,1), visualize=True)\n",
    "# hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0,10))\n",
    "\n",
    "# # Overlay HOG on the face region\n",
    "# # addon = np.stack((hog_image_rescaled,)*3, axis=-1)\n",
    "# addon = hog_image_rescaled\n",
    "# addon = (addon*255).astype(np.uint8)\n",
    "# # addon_padded = np.zeros_like(image1)\n",
    "# # addon_padded[y:y+h, x:x+w] = addon\n",
    "# combined = cv2.add(combined, addon)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "# axes[0].imshow(combined, cmap='gray')\n",
    "\n",
    "# combined = image2\n",
    "\n",
    "# fd, hog_image = hog(image2, orientations=8, pixels_per_cell=(16,16),\n",
    "#                     cells_per_block=(1,1), visualize=True)\n",
    "# hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0,10))\n",
    "\n",
    "\n",
    "# addon = hog_image_rescaled\n",
    "# addon = (addon*255).astype(np.uint8)\n",
    "# combined = cv2.add(combined, addon)\n",
    "\n",
    "# axes[1].imshow(addon, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
